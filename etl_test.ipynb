{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.awsAccessKeyId\", os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.awsSecretAccessKey\", os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e52fa914b53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlog_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_data_table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msong_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://udacity-dend/song_data/*/*/*/*.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0msong_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"song_data_table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "spark = create_spark_session()\n",
    "\n",
    "log_data = spark.read.json(\"s3a://udacity-dend/log_data/*/*/*.json\")\n",
    "log_data = log_data[log_data.page == 'NextSong']  \n",
    "log_data = log_data.withColumn('timestamp', F.to_timestamp(log_data.ts/1000))\n",
    "log_data = log_data.withColumn('datetime', F.to_date(log_data.timestamp))\n",
    "log_data = log_data.withColumn('uniqueId', monotonically_increasing_id())\n",
    "log_data.createOrReplaceTempView(\"log_data_table\")\n",
    "\n",
    "song_data = spark.read.json(\"s3a://udacity-dend/song_data/*/*/*/*.json\")\n",
    "song_data.createOrReplaceTempView(\"song_data_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (20...|ARTC1LV1187B9A4858|1972|301.40036|\n",
      "|SOKTJDS12AF72A25E5|Drown In My Own T...|ARA23XO1187B9AF18F|   0|  192.522|\n",
      "|SOEKAZG12AB018837E|I'll Slap Your Fa...|ARSVTNL1187B992A91|2001|129.85424|\n",
      "|SOQPWCR12A6D4FB2A3|A Poor Recipe For...|AR73AIO1187B9AD57B|2005|118.07302|\n",
      "|SOBRKGM12A8C139EF6|Welcome to the Pl...|ARXQBR11187B98A2CC|1985|821.05424|\n",
      "|SORRNOC12AB017F52B|The Last Beat Of ...|ARSZ7L31187FB4E610|2004|337.81506|\n",
      "|SOHKNRJ12A6701D1F8|        Drop of Rain|AR10USD1187B99F3F1|   0|189.57016|\n",
      "|SOAPERH12A58A787DC|The One And Only ...|ARZ5H0P1187B98A1DD|   0|230.42567|\n",
      "|SOSMJFC12A8C13DE0C|Is That All There...|AR1KTV21187B9ACD72|   0|343.87546|\n",
      "|SOOVHYF12A8C134892|     I'll Be Waiting|ARCLYBR1187FB53913|1989|304.56118|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = song_data.select('song_id', 'title', 'artist_id', 'year', 'duration').limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|ARTC1LV1187B9A4858|  The Bonzo Dog Band|Goldsmith's Colle...|        51.4536|        -0.01802|\n",
      "|ARA23XO1187B9AF18F|     The Smithereens|Carteret, New Jersey|       40.57885|       -74.21956|\n",
      "|ARSVTNL1187B992A91|       Jonathan King|     London, England|       51.50632|        -0.12714|\n",
      "|AR73AIO1187B9AD57B|   Western Addiction|   San Francisco, CA|       37.77916|      -122.42005|\n",
      "|ARXQBR11187B98A2CC|Frankie Goes To H...|  Liverpool, England|           null|            null|\n",
      "|ARSZ7L31187FB4E610|           Devotchka|          Denver, CO|       39.74001|      -104.99226|\n",
      "|AR10USD1187B99F3F1|Tweeterfriendly M...|Burlington, Ontar...|           null|            null|\n",
      "|ARZ5H0P1187B98A1DD|          Snoop Dogg|      Long Beach, CA|       33.76672|       -118.1924|\n",
      "|AR1KTV21187B9ACD72|            Cristina|     California - LA|       34.05349|      -118.24532|\n",
      "|ARCLYBR1187FB53913|          Neal Schon|       San Mateo, CA|       37.54703|      -122.31483|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = song_data.select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude').limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+------+-----+\n",
      "|userId| firstName|lastName|gender|level|\n",
      "+------+----------+--------+------+-----+\n",
      "|    10|    Sylvie|    Cruz|     F| free|\n",
      "|    53|   Celeste|Williams|     F| free|\n",
      "|    53|   Celeste|Williams|     F| free|\n",
      "|    53|   Celeste|Williams|     F| free|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "|    29|Jacqueline|   Lynch|     F| paid|\n",
      "+------+----------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table = log_data.select('userId', 'firstName', 'lastName', 'gender', 'level').limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+---+----+-----+----+-------+\n",
      "|           timestamp|start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----------+----+---+----+-----+----+-------+\n",
      "|2018-11-12 02:37:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:37:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:42:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:45:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:47:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:50:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:54:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 02:57:...|2018-11-12|   2| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 03:00:...|2018-11-12|   3| 12|  46|   11|2018|      0|\n",
      "|2018-11-12 03:03:...|2018-11-12|   3| 12|  46|   11|2018|      0|\n",
      "+--------------------+----------+----+---+----+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table = spark.sql(\"\"\"\n",
    "        select timestamp\n",
    "        , datetime AS start_time\n",
    "        , hour(timestamp) AS hour\n",
    "        , day(timestamp) AS day\n",
    "        , weekofyear(timestamp) AS week\n",
    "        , month(timestamp) AS month\n",
    "        , year(timestamp) AS year\n",
    "        , weekday(timestamp) AS weekday\n",
    "        from log_data_table\n",
    "    \"\"\").limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------+-----+-------+---------+---------+--------------------+--------------------+\n",
      "|songplay_id|   start_time|userId|level|song_id|artist_id|sessionId|            location|           userAgent|\n",
      "+-----------+-------------+------+-----+-------+---------+---------+--------------------+--------------------+\n",
      "|         12|1542012644796|   100| free|   null|     null|      428|New York-Newark-J...|\"Mozilla/5.0 (Mac...|\n",
      "|        110|1542049762796|    73| paid|   null|     null|      294|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|\n",
      "|         91|1542046045796|    33| free|   null|     null|      399|          Eugene, OR|\"Mozilla/5.0 (Win...|\n",
      "|          9|1541991804796|    29| paid|   null|     null|      389|Atlanta-Sandy Spr...|\"Mozilla/5.0 (Mac...|\n",
      "|        160|1542063919796|    80| paid|   null|     null|      481|Portland-South Po...|\"Mozilla/5.0 (Mac...|\n",
      "|         61|1542039844796|    97| paid|   null|     null|      374|Lansing-East Lans...|\"Mozilla/5.0 (X11...|\n",
      "|        133|1542056191796|    58| paid|   null|     null|      494|Augusta-Richmond ...|\"Mozilla/5.0 (Win...|\n",
      "|        138|1542056841796|    58| paid|   null|     null|      494|Augusta-Richmond ...|\"Mozilla/5.0 (Win...|\n",
      "|         85|1542045013796|    32| free|   null|     null|      505|New York-Newark-J...|\"Mozilla/5.0 (Win...|\n",
      "|         99|1542048012796|    73| paid|   null|     null|      294|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|\n",
      "+-----------+-------------+------+-----+-------+---------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplay_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        stg.uniqueId AS songplay_id,\n",
    "        stg.ts AS start_time,\n",
    "        stg.userId,\n",
    "        stg.level,\n",
    "        stg2.song_id,\n",
    "        stg2.artist_id,\n",
    "        stg.sessionId,\n",
    "        stg.location,\n",
    "        stg.userAgent\n",
    "    FROM log_data_table stg\n",
    "    LEFT JOIN song_data_table stg2\n",
    "        ON stg.artist = stg2.artist_name\n",
    "        AND stg.song = stg2.title\n",
    "        AND stg.length = stg2.duration\n",
    "    WHERE stg.userId IS NOT NULL\n",
    "\"\"\").limit(10).show()\n",
    "\n",
    "#songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
